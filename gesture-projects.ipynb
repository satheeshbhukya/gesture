{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9860393,"sourceType":"datasetVersion","datasetId":6051529}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train=torch.load('/kaggle/input/gesture/train.pt',weights_only=True) \ntest=torch.load('/kaggle/input/gesture/test.pt',weights_only=True)  \nval=torch.load('/kaggle/input/gesture/val.pt',weights_only=True) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(\"train:\",train) \nprint(\"test:\",test)\nprint(\"val:\",val)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train.keys())\nprint(test.keys())\nprint(val.keys())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract the data and labels\ntrain_samples, train_labels = train['samples'], train['labels']\nval_samples, val_labels = val['samples'], val['labels']\ntest_samples, test_labels = test['samples'], test['labels'] \n\nprint(\"train:\",train_samples.shape,train_labels.shape) \nprint(\"val:\",val_samples.shape,val_labels.shape)\nprint(\"test:\",test_samples.shape,test_labels.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_samples[0])  \nprint(train_labels[0]) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_samples = train_samples.float()  # Convert to float32\nval_samples = val_samples.float()      # Convert to float32\ntest_samples = test_samples.float()    # Convert to float32","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_samples.dtype)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalize and convert to float32\ntrain_samples = train_samples / train_samples.max()\nval_samples = val_samples / val_samples.max()\ntest_samples = test_samples / test_samples.max()\n\n# Calculate mean and std using train_samples\ntrain_mean = train_samples.mean(dim=[0, 2], keepdim=True)  # Mean for each channel (over batch and time)\ntrain_std = train_samples.std(dim=[0, 2], keepdim=True)    # Std for each channel (over batch and time)\n\n# Standardize the train_samples, val_samples, and test_samples using train_mean and train_std\ntrain_samples = (train_samples - train_mean) / train_std\nval_samples = (val_samples - train_mean) / train_std  # Use train mean and std for val_samples\ntest_samples = (test_samples - train_mean) / train_std  # Use train mean and std for test_samples\n\n# Convert to float32\n# train_samples = train_samples.float()\n# val_samples = val_samples.float()\n# test_samples = test_samples.float()\n\n# Check the shapes and types\nprint(train_samples.shape, train_samples.dtype)\nprint(val_samples.shape, val_samples.dtype)\nprint(test_samples.shape, test_samples.dtype) \n\nprint(\"Train mean:\", train_mean)\nprint(\"Train std:\", train_std)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to check for NaN values in the tensor\ndef check_for_missing_values(data_tensor, dataset_name=\"Dataset\"):\n    # Check for NaN values\n    nan_values = torch.isnan(data_tensor)\n\n    # Check if there are any NaN values\n    if nan_values.any():\n        print(f\"{dataset_name} has missing (NaN) values.\")\n    else:\n        print(f\"{dataset_name} has no missing values.\")\n\n    # Optionally, print the indices where NaNs are located (can be large if the tensor is big)\n    nan_indices = torch.nonzero(nan_values)\n    if nan_indices.numel() > 0:\n        print(f\"Indices of NaN values in {dataset_name}:\")\n        print(nan_indices)\n\n# Check for missing values in train, validation, and test datasets\ncheck_for_missing_values(train_samples, \"Train Samples\")\ncheck_for_missing_values(val_samples, \"Validation Samples\")\ncheck_for_missing_values(test_samples, \"Test Samples\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reshape to (batch_size, sequence_length, input_size) \ntrain_samples = train_samples.permute(0, 2, 1).to(device)\nval_samples = val_samples.permute(0, 2, 1).to(device)\ntest_samples = test_samples.permute(0, 2, 1).to(device) \nprint(train_samples.shape) \nprint(val_samples.shape)\nprint(test_samples.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming you have a labels tensor (train_labels, val_labels, or test_labels)\nunique_labels = torch.unique(train_labels)  # You can also use val_labels or test_labels\nprint(f\"Unique labels: {unique_labels}\")\nnum_classes = len(unique_labels)\nprint(f\"Number of classes: {num_classes}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.cuda.amp import GradScaler, autocast\n\n# Device Configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Self-Supervised Learning Encoder Model\nclass ContrastiveEncoder(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(ContrastiveEncoder, self).__init__()\n        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2, batch_first=True, bidirectional=True)\n\n    def forward(self, x):\n        out, _ = self.lstm(x)\n        return out[:, -1, :]  # Last hidden state as representation\n\n# Contrastive Loss for Self-Supervised Learning\nclass ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n        loss = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n                          (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        return loss\n\n# Initialize the encoder\ninput_size = 3\nhidden_size = 128\nencoder = ContrastiveEncoder(input_size=input_size, hidden_size=hidden_size).to(device)\ncontrastive_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\ncontrastive_criterion = ContrastiveLoss()\n\n# Contrastive Learning Dataset Preparation (Self-Supervised)\ndef create_pairs(data, labels):\n    pairs, pair_labels = [], []\n    for i in range(len(data)):\n        for j in range(len(data)):\n            if i != j:\n                pairs.append((data[i], data[j]))\n                pair_labels.append(1 if labels[i] == labels[j] else 0)\n    return torch.stack([p[0] for p in pairs]), torch.stack([p[1] for p in pairs]), torch.tensor(pair_labels).to(device)\n\n# Create pairs and prepare DataLoader\ntrain_sample1, train_sample2, train_pair_labels = create_pairs(train_samples, train_labels)\n\n# Contrastive learning data loader\nbatch_size = 32\ntrain_dataset = TensorDataset(train_sample1, train_sample2, train_pair_labels)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Train the encoder with contrastive loss and AMP\nscaler = GradScaler()  # For automatic mixed precision\ndef train_encoder(encoder, data_loader, criterion, optimizer, num_epochs=10):\n    encoder.train()\n    for epoch in range(num_epochs):\n        total_loss = 0\n        for sample1, sample2, labels in data_loader:\n            sample1, sample2, labels = sample1.to(device), sample2.to(device), labels.float().to(device)\n            optimizer.zero_grad()\n            with autocast():  # Use AMP for faster training\n                output1, output2 = encoder(sample1), encoder(sample2)\n                loss = criterion(output1, output2, labels)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            total_loss += loss.item()\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(data_loader):.4f}\")\n\ntrain_encoder(encoder, train_loader, contrastive_criterion, contrastive_optimizer, num_epochs=10)\n\n# Classification Model using Learned Representations\nclass GestureClassifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super(GestureClassifier, self).__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(2 * hidden_size, num_classes)\n\n    def forward(self, x):\n        with torch.no_grad():  # Freeze encoder for classification task\n            x = self.encoder(x)\n        return self.fc(x)\n\nnum_classes = 8\nclassifier = GestureClassifier(encoder, num_classes).to(device)\nclassification_optimizer = optim.Adam(classifier.parameters(), lr=0.001)\nclassification_criterion = nn.CrossEntropyLoss()\n\n# Classification DataLoader\ntrain_classification_dataset = TensorDataset(train_samples, train_labels)\ntrain_classification_loader = DataLoader(train_classification_dataset, batch_size=batch_size, shuffle=True)\nval_classification_dataset = TensorDataset(val_samples, val_labels)\nval_classification_loader = DataLoader(val_classification_dataset, batch_size=batch_size)\n\n# Training Function for Classification Model with Early Stopping\ndef train_classifier(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, patience=3):\n    model.train()\n    best_accuracy = 0\n    patience_counter = 0\n    \n    for epoch in range(num_epochs):\n        for samples, labels in train_loader:\n            samples, labels = samples.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(samples)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n        # Validation with Early Stopping\n        val_accuracy = evaluate_model(model, val_loader)\n        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {val_accuracy:.2f}%')\n        \n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            patience_counter = 0  # Reset patience counter if accuracy improves\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= patience:\n            print(\"Early stopping due to no improvement.\")\n            break\n\n# Evaluation function for the classification model\ndef evaluate_model(model, data_loader):\n    model.eval()\n    correct = total = 0\n    with torch.no_grad():\n        for samples, labels in data_loader:\n            samples, labels = samples.to(device), labels.to(device)\n            outputs = model(samples)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = 100 * correct / total\n    return accuracy\n\n# Train and Evaluate the Classifier\ntrain_classifier(classifier, train_classification_loader, val_classification_loader, classification_criterion, classification_optimizer, num_epochs=10)\n\n# Final Test Accuracy\ntest_classification_dataset = TensorDataset(test_samples, test_labels)\ntest_classification_loader = DataLoader(test_classification_dataset, batch_size=batch_size)\ntest_accuracy = evaluate_model(classifier, test_classification_loader)\nprint(f'Test Accuracy: {test_accuracy:.2f}%')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}